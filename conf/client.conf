#### block cache
# {
# block_cache.cache_store:
#   cache store type, none, disk or 3fs
#
# block_cache.stage_bandwidth_throttle_enable:
#   block will been put to s3 storage directly if disk write bandwidth
#   exceed limit.
#
# disk_cache.cache_dir:
#   directory for store cache block, multi directories
#   and corresponding max size are supported, e.g. "/data1:200;/data2:300"
#
# disk_cache.ioring_iodepth:
#   iodepth for io ring (works for both linux io uring and 3fs usrbio)
block_cache.cache_store=disk
block_cache.enable_stage=true
block_cache.enable_cache=true
block_cache.trace_logging=true
block_cache.upload_stage_throttle_enable=false
block_cache.upload_stage_throttle_bandwidth_mb=256
block_cache.upload_stage_throttle_iops=100
block_cache.upload_stage_max_inflights=32
block_cache.prefetch_max_inflights=100
block_cache.storage_upload_retry_timeout_s=1800
block_cache.storage_download_retry_timeout_s=1800

disk_cache.cache_dir=.  # __DINGOADM_TEMPLATE__ /dingofs/client/data/cache __DINGOADM_TEMPLATE__
disk_cache.cache_size_mb=102400
disk_cache.free_space_ratio=0.1
disk_cache.cache_expire_s=259200
disk_cache.cleanup_expire_interval_ms=1000
disk_cache.ioring_iodepth=128

disk_state.tick_duration_s=60
disk_state.normal2unstable_error_num=3
disk_state.unstable2normal_succ_num=10
disk_state.unstable2down_s=1800
disk_state.check_duration_ms=3000
# }

#### remote cache
# {
remote_cache.cache_group=
remote_cache.mds_addrs=127.0.0.1:6900
remote_cache.mds_rpc_timeout_ms=3000
remote_cache.mds_rpc_retry_times=1
remote_cache.mds_request_retry_times=3
remote_cache.load_members_interval_ms=1000

remote_cache.fill_group_cache=true
remote_cache.subrequest_range_size=1048576
remote_cache.rpc_connect_timeout_ms=1000
remote_cache.rpc_connect_timeout_as_unreachable=10
remote_cache.rpc_max_connection_pool_size=256
remote_cache.put_rpc_timeout_ms=30000
remote_cache.range_rpc_timeout_ms=30000
remote_cache.cache_rpc_timeout_ms=30000
remote_cache.prefetch_rpc_timeout_ms=3000
remote_cache.ping_rpc_timeout_ms=1000
remote_cache.rpc_max_retry_time=3
remote_cache.rpc_max_timeout_ms=60000

cache_node_state.tick_duration_s=30
cache_node_state.normal2unstable_error_num=10
cache_node_state.unstable2normal_succ_num=3
cache_node_state.check_duration_ms=3000
# }

#### control fuse module
# {
# fuse.conn_info.*:
#   Connnection information, one instance per mountpoint
#
# fuse.file_info.*:
#   Information about an open file, one instance per open file
#
# fuse.conn_info.want_splice_*:
#   splice will bring higher performance in some cases
#   but there might be a kernel issue that will cause kernel panic when enabling it
#   see https://lore.kernel.org/all/CAAmZXrsGg2xsP1CK+cbuEMumtrqdvD-NKnWzhNcvn71RV3c1yw@mail.gmail.com/
#   until this issue has been fixed, splice should be disabled
fuse.conn_info.want_splice_move=false
fuse.conn_info.want_splice_read=false
fuse.conn_info.want_splice_write=false
fuse.conn_info.want_auto_inval_data=true
fuse.file_info.direct_io=false
fuse.file_info.keep_cache=true
# }

#### Memrory page allocator
# {
#
data_stream.page.size=65536
data_stream.page.total_size_mb=1024
data_stream.page.use_pool=true
# }

#### aws sdk
# {
#
s3.region=us-east-1
s3.useVirtualAddressing=false
# Off = 0,Fatal = 1,Error = 2,Warn = 3,Info = 4,Debug = 5,Trace = 6
s3.logLevel=4
s3.verify_SSL=False
s3.maxConnections=32
s3.connectTimeout=60000
s3.requestTimeout=10000
s3.use_crt_client=true
# this only work when use_crt_client is false
s3.use_thread_pool=false
# this only work when use_crt_client is false and use_thread_pool is true
s3.async_thread_num_in_thread_pool=256
s3.enableTelemetry=false
# }

#### block throttle
# {
#
s3.throttle.iopsTotalLimit=0
s3.throttle.iopsReadLimit=0
s3.throttle.iopsWriteLimit=0
s3.throttle.bpsTotalMB=0
s3.throttle.bpsReadMB=0
s3.throttle.bpsWriteMB=0
# limit all inflight async requests' bytes, |0| means not limited
s3.maxAsyncRequestInflightBytes=104857600
# }

#### log related
# {
#
client.common.logDir=/data/logs/dingofs  # __DINGOADM_TEMPLATE__ /dingofs/client/logs __DINGOADM_TEMPLATE__
# as the number increases, it becomes more and more detailed
client.loglevel=0
# }

#### brpc
# {
#
# close socket after defer.close.second
rpc.defer.close.second=1
# rpc health check interval in second, 0 or negative value means disable health check
rpc.healthCheckIntervalSec=3
# }

mds.addr=172.20.61.102:7801

### uds
uds.fdCommPath=/var/run # unix domain socket file path

### block access related options

block_access.rados.rados_op_timeout=120

### vfs data related options

# vfs.data.writeback_suffix:
#   file with the specified suffix will use writeback write policy,
#   multi suffixs supported, e.g. .pt:.ckpt
vfs.data.writeback_suffix=
vfs.data.writeback=false
vfs.data.flush_bg_thread=16
vfs.data.vfs_periodic_flush_interval_ms=100

vfs.data.single_tread_read=false
# only work when vfs.data.single_thread_read is false
vfs.data.read_executor_thread=8

#prefetch config
vfs.prefetch.enable=true
vfs.prefetch.threads=8

# warmup config
vfs.warmup.threads=4
vfs.intime_warmup.enbale=false
vfs.intime_warmup.restart_mtime_interval_secs=120 #2min
vfs.intime_warmup.restart_trigger_interval_secs=1800 #30min

### vfs meta related options
vfs.meta.max_name_length=255  # max length of file name

# Default 0, the worker num of bthread whill be #cpu-cores
vfs.bthread_worker_num=0
vfs.dummy_server.port=10000

# related loggging
vfs.access_logging=true
vfs.access_log_threshold_us=0
vfs.vfs_meta_logging=true
vfs.vfs_meta_log_threshold_us=1000

vfs.trace_logging=false
